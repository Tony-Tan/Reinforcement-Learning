<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="content-type" content="text/html;charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link id="highlight-style" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>

    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/contrib/auto-render.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked@3.0.7/marked.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;600&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Consolas:wght@400&display=swap" rel="stylesheet">
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false}
                ]
            });
            document.querySelectorAll('span.code-content').forEach((block) => {
                hljs.highlightElement(block); });

        });
    </script>
</head>
<body>
    <div id="container">
        <div id="background"></div>
        <div class="section">
        <div class="docs">
            <p>
                <a class="parent" href="/">home</a>
            </p>
            <p>
                <a href="https://github.com/Tony-Tan/Reinforcement-Learning" target="_blank">
                    <img alt="Github" src="https://img.shields.io/github/stars/Tony-Tan/Reinforcement-Learning?style=social" style="max-width:100%;"></a>
                <a href="https://twitter.com/anthony_s_tan" rel="nofollow" target="_blank">
                    <img alt="Twitter" src="https://img.shields.io/twitter/follow/anthony_s_tan?style=social" style="max-width:100%;"></a>
            </p>
            <p>
                <a href="https://github.com/Tony-Tan/Reinforcement-Learning" target="_blank">
                    View code on Github</a>
            </p>
        </div>
    </div>
        
            <div class="section" id="section-1">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-1">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-1"></div>
                    <script>
                        document.getElementById('description-section-1').innerHTML = marked(`self.optimizer = torch.optim.RMSprop(self.value_nn.parameters(), lr=learning_rate, momentum=0.95,alpha=0.95, eps=0.01)`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">1</span> <span class="code-content language-python">import cv2</span></span>
                    
                        <span class="line"><span class="line-number">2</span> <span class="code-content language-python">import numpy as np</span></span>
                    
                        <span class="line"><span class="line-number">3</span> <span class="code-content language-python">import torch.optim</span></span>
                    
                        <span class="line"><span class="line-number">4</span> <span class="code-content language-python">import torch.nn.functional as F</span></span>
                    
                        <span class="line"><span class="line-number">5</span> <span class="code-content language-python">from collections import deque</span></span>
                    
                        <span class="line"><span class="line-number">6</span> <span class="code-content language-python">from abc_rl.agent import Agent</span></span>
                    
                        <span class="line"><span class="line-number">7</span> <span class="code-content language-python">from models.dqn_networks import DQNAtari</span></span>
                    
                        <span class="line"><span class="line-number">8</span> <span class="code-content language-python">from abc_rl.policy import *</span></span>
                    
                        <span class="line"><span class="line-number">9</span> <span class="code-content language-python">from abc_rl.exploration import *</span></span>
                    
                        <span class="line"><span class="line-number">10</span> <span class="code-content language-python">from experience_replay.uniform_experience_replay import *</span></span>
                    
                        <span class="line"><span class="line-number">11</span> <span class="code-content language-python">from abc_rl.perception_mapping import *</span></span>
                    
                        <span class="line"><span class="line-number">12</span> <span class="code-content language-python">from abc_rl.reward_shaping import *</span></span>
                    
                        <span class="line"><span class="line-number">13</span> <span class="code-content language-python">from exploration.epsilon_greedy import *</span></span>
                    
                        <span class="line"><span class="line-number">14</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">15</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">16</span> <span class="code-content language-python">def image_normalization(image_uint8):</span></span>
                    
                        <span class="line"><span class="line-number">17</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">18</span> <span class="code-content language-python">    return image_uint8 / 255.0 - .5</span></span>
                    
                        <span class="line"><span class="line-number">19</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">20</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">21</span> <span class="code-content language-python">class DQNAtariReward(RewardShaping):</span></span>
                    
                        <span class="line"><span class="line-number">22</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">23</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">24</span> <span class="code-content language-python">    def __init__(self):</span></span>
                    
                        <span class="line"><span class="line-number">25</span> <span class="code-content language-python">        super().__init__()</span></span>
                    
                        <span class="line"><span class="line-number">26</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">27</span> <span class="code-content language-python">    def __call__(self, reward):</span></span>
                    
                        <span class="line"><span class="line-number">28</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">29</span> <span class="code-content language-python">        return np.clip(reward, a_min=-1, a_max=1)</span></span>
                    
                        <span class="line"><span class="line-number">30</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">31</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">32</span> <span class="code-content language-python">class DQNPerceptionMapping(PerceptionMapping):</span></span>
                    
                        <span class="line"><span class="line-number">33</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">34</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">35</span> <span class="code-content language-python">    def __init__(self, phi_channel: int, input_frame_width: int,</span></span>
                    
                        <span class="line"><span class="line-number">36</span> <span class="code-content language-python">                 input_frame_height: int):</span></span>
                    
                        <span class="line"><span class="line-number">37</span> <span class="code-content language-python">        super().__init__()</span></span>
                    
                        <span class="line"><span class="line-number">38</span> <span class="code-content language-python">        self.phi = deque(maxlen=phi_channel)</span></span>
                    
                        <span class="line"><span class="line-number">39</span> <span class="code-content language-python">        self.phi_channel = phi_channel</span></span>
                    
                        <span class="line"><span class="line-number">40</span> <span class="code-content language-python">        self.input_frame_width = input_frame_width</span></span>
                    
                        <span class="line"><span class="line-number">41</span> <span class="code-content language-python">        self.input_frame_height = input_frame_height</span></span>
                    
                        <span class="line"><span class="line-number">42</span> <span class="code-content language-python">        self.last_frame_pre_process = None</span></span>
                    
                        <span class="line"><span class="line-number">43</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">44</span> <span class="code-content language-python">    def __pre_process(self, obs: np.ndarray):</span></span>
                    
                        <span class="line"><span class="line-number">45</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">46</span> <span class="code-content language-python">        img_y_channel = cv2.cvtColor(obs, cv2.COLOR_BGR2YUV)[:, :, 0]</span></span>
                    
                        <span class="line"><span class="line-number">47</span> <span class="code-content language-python">        if self.last_frame_pre_process is not None:</span></span>
                    
                        <span class="line"><span class="line-number">48</span> <span class="code-content language-python">            obs_y = np.maximum(self.last_frame_pre_process, img_y_channel)</span></span>
                    
                        <span class="line"><span class="line-number">49</span> <span class="code-content language-python">        else:</span></span>
                    
                        <span class="line"><span class="line-number">50</span> <span class="code-content language-python">            obs_y = self.last_frame_pre_process = img_y_channel</span></span>
                    
                        <span class="line"><span class="line-number">51</span> <span class="code-content language-python">        self.last_frame_pre_process = img_y_channel</span></span>
                    
                        <span class="line"><span class="line-number">52</span> <span class="code-content language-python">        obs_processed = cv2.resize(obs_y, (self.input_frame_width, self.input_frame_height))</span></span>
                    
                        <span class="line"><span class="line-number">53</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">54</span> <span class="code-content language-python">        return obs_processed</span></span>
                    
                        <span class="line"><span class="line-number">55</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">56</span> <span class="code-content language-python">    def __phi_append(self, obs: np.ndarray):</span></span>
                    
                        <span class="line"><span class="line-number">57</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">58</span> <span class="code-content language-python">        self.phi.append(obs)</span></span>
                    
                        <span class="line"><span class="line-number">59</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">60</span> <span class="code-content language-python">    def reset(self):</span></span>
                    
                        <span class="line"><span class="line-number">61</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">62</span> <span class="code-content language-python">        self.last_frame_pre_process = None</span></span>
                    
                        <span class="line"><span class="line-number">63</span> <span class="code-content language-python">        self.phi.clear()</span></span>
                    
                        <span class="line"><span class="line-number">64</span> <span class="code-content language-python">        for i in range(self.phi_channel):</span></span>
                    
                        <span class="line"><span class="line-number">65</span> <span class="code-content language-python">            self.phi.append(np.zeros([self.input_frame_width, self.input_frame_width]))</span></span>
                    
                        <span class="line"><span class="line-number">66</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">67</span> <span class="code-content language-python">    def __call__(self, state: np.ndarray, step_i: int) -> np.ndarray:</span></span>
                    
                        <span class="line"><span class="line-number">68</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">69</span> <span class="code-content language-python">        if step_i == 0:</span></span>
                    
                        <span class="line"><span class="line-number">70</span> <span class="code-content language-python">            self.reset()</span></span>
                    
                        <span class="line"><span class="line-number">71</span> <span class="code-content language-python">        self.__phi_append(self.__pre_process(state))</span></span>
                    
                        <span class="line"><span class="line-number">72</span> <span class="code-content language-python">        obs = np.array(self.phi, dtype=np.uint8)</span></span>
                    
                        <span class="line"><span class="line-number">73</span> <span class="code-content language-python">        return obs</span></span>
                    
                        <span class="line"><span class="line-number">74</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">75</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">76</span> <span class="code-content language-python">class DQNValueFunction(ValueFunction):</span></span>
                    
                        <span class="line"><span class="line-number">77</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">78</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">79</span> <span class="code-content language-python">    def __init__(self, input_channel: int, action_dim: int, learning_rate: float,</span></span>
                    
                        <span class="line"><span class="line-number">80</span> <span class="code-content language-python">                 gamma: float, step_c: int, model_saving_period: int, device: torch.device, logger: Logger):</span></span>
                    
                        <span class="line"><span class="line-number">81</span> <span class="code-content language-python">        super(DQNValueFunction, self).__init__()</span></span>
                    
                        <span class="line"><span class="line-number">82</span> <span class="code-content language-python">        self.logger = logger</span></span>
                    
                        <span class="line"><span class="line-number">83</span> <span class="code-content language-python">        self.value_nn = DQNAtari(input_channel, action_dim).to(device)</span></span>
                    
                        <span class="line"><span class="line-number">84</span> <span class="code-content language-python">        self.target_value_nn = DQNAtari(input_channel, action_dim).to(device)</span></span>
                    
                        <span class="line"><span class="line-number">85</span> <span class="code-content language-python">        self.target_value_nn.eval()</span></span>
                    
                        <span class="line"><span class="line-number">86</span> <span class="code-content language-python">        self.synchronize_value_nn()</span></span>
                    
                        <span class="line"><span class="line-number">87</span> <span class="code-content language-python">        self.optimizer = torch.optim.Adam(self.value_nn.parameters(), lr=learning_rate)</span></span>
                    
                        <span class="line"><span class="line-number">90</span> <span class="code-content language-python">        self.learning_rate = learning_rate</span></span>
                    
                        <span class="line"><span class="line-number">91</span> <span class="code-content language-python">        self.gamma = gamma</span></span>
                    
                        <span class="line"><span class="line-number">92</span> <span class="code-content language-python">        self.device = device</span></span>
                    
                        <span class="line"><span class="line-number">93</span> <span class="code-content language-python">        self.update_step = 0</span></span>
                    
                        <span class="line"><span class="line-number">94</span> <span class="code-content language-python">        self.step_c = step_c</span></span>
                    
                        <span class="line"><span class="line-number">95</span> <span class="code-content language-python">        self.model_saving_period = model_saving_period</span></span>
                    
                        <span class="line"><span class="line-number">96</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">97</span> <span class="code-content language-python">    def synchronize_value_nn(self):</span></span>
                    
                        <span class="line"><span class="line-number">98</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">99</span> <span class="code-content language-python">        self.target_value_nn.load_state_dict(self.value_nn.state_dict())</span></span>
                    
                        <span class="line"><span class="line-number">100</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">101</span> <span class="code-content language-python">    def max_state_value(self, obs_tensor):</span></span>
                    
                        <span class="line"><span class="line-number">102</span> <span class="code-content language-python">        with torch.no_grad():</span></span>
                    
                        <span class="line"><span class="line-number">103</span> <span class="code-content language-python">            obs_tensor = image_normalization(obs_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">104</span> <span class="code-content language-python">            outputs = self.target_value_nn(obs_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">105</span> <span class="code-content language-python">        msv, _ = torch.max(outputs, dim=1, keepdim=True)</span></span>
                    
                        <span class="line"><span class="line-number">106</span> <span class="code-content language-python">        return msv</span></span>
                    
                        <span class="line"><span class="line-number">107</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">108</span> <span class="code-content language-python">    def update(self, samples: list, weight=None):</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-2">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-2">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-2"></div>
                    <script>
                        document.getElementById('description-section-2').innerHTML = marked(`stream = torch.cuda.Stream(device=self.device)with torch.cuda.stream(stream):`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">112</span> <span class="code-content language-python">        obs_tensor = samples[0].to(self.device, non_blocking=True)</span></span>
                    
                        <span class="line"><span class="line-number">113</span> <span class="code-content language-python">        action_tensor = samples[1].to(self.device, non_blocking=True)</span></span>
                    
                        <span class="line"><span class="line-number">114</span> <span class="code-content language-python">        reward_tensor = samples[2].to(self.device, non_blocking=True)</span></span>
                    
                        <span class="line"><span class="line-number">115</span> <span class="code-content language-python">        next_obs_tensor = samples[3].to(self.device, non_blocking=True)</span></span>
                    
                        <span class="line"><span class="line-number">116</span> <span class="code-content language-python">        termination_tensor = samples[4].to(self.device, non_blocking=True)</span></span>
                    
                        <span class="line"><span class="line-number">117</span> <span class="code-content language-python">        truncated_tensor = samples[5].to(self.device, non_blocking=True)</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-3">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-3">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-3"></div>
                    <script>
                        document.getElementById('description-section-3').innerHTML = marked(`stream.synchronize()`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">121</span> <span class="code-content language-python">        max_next_state_value = self.max_state_value(next_obs_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">122</span> <span class="code-content language-python">        reward_tensor.resize_as_(max_next_state_value)</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-4">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-4">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-4"></div>
                    <script>
                        document.getElementById('description-section-4').innerHTML = marked(`calculate q value`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">124</span> <span class="code-content language-python">        truncated_tensor.resize_as_(max_next_state_value)</span></span>
                    
                        <span class="line"><span class="line-number">125</span> <span class="code-content language-python">        termination_tensor.resize_as_(max_next_state_value)</span></span>
                    
                        <span class="line"><span class="line-number">126</span> <span class="code-content language-python">        q_value = reward_tensor + self.gamma * max_next_state_value * (1 - truncated_tensor) * (1 - termination_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">127</span> <span class="code-content language-python">        action_tensor.resize_as_(reward_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">128</span> <span class="code-content language-python">        q_value.resize_as_(reward_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">129</span> <span class="code-content language-python">        actions = action_tensor.long()</span></span>
                    
                        <span class="line"><span class="line-number">130</span> <span class="code-content language-python">        self.optimizer.zero_grad()</span></span>
                    
                        <span class="line"><span class="line-number">131</span> <span class="code-content language-python">        self.value_nn.train()</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-5">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-5">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-5"></div>
                    <script>
                        document.getElementById('description-section-5').innerHTML = marked(`normalize the input image`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">133</span> <span class="code-content language-python">        obs_tensor = image_normalization(obs_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">134</span> <span class="code-content language-python">        outputs = self.value_nn(obs_tensor)</span></span>
                    
                        <span class="line"><span class="line-number">135</span> <span class="code-content language-python">        obs_action_value = outputs.gather(1, actions)</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-6">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-6">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-6"></div>
                    <script>
                        document.getElementById('description-section-6').innerHTML = marked(`loss = F.mse_loss(q_value, obs_action_value)Clip the difference between obs_action_value and q_value to the range of -1 to 1`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">138</span> <span class="code-content language-python">        diff = obs_action_value - q_value</span></span>
                    
                        <span class="line"><span class="line-number">139</span> <span class="code-content language-python">        if weight is not None:</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-7">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-7">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-7"></div>
                    <script>
                        document.getElementById('description-section-7').innerHTML = marked(`for the prioritized experience replay`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">141</span> <span class="code-content language-python">            weight = torch.as_tensor(weight, device=self.device, dtype=torch.float32).resize_as_(diff)</span></span>
                    
                        <span class="line"><span class="line-number">142</span> <span class="code-content language-python">            diff_clipped = torch.clip(diff, -1, 1) * weight</span></span>
                    
                        <span class="line"><span class="line-number">143</span> <span class="code-content language-python">        else:</span></span>
                    
                        <span class="line"><span class="line-number">144</span> <span class="code-content language-python">            diff_clipped = torch.clip(diff, -1, 1)</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-8">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-8">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-8"></div>
                    <script>
                        document.getElementById('description-section-8').innerHTML = marked(`Use the clipped difference for the loss calculation`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">147</span> <span class="code-content language-python">        loss = F.mse_loss(diff_clipped, torch.zeros_like(diff_clipped))</span></span>
                    
                        <span class="line"><span class="line-number">148</span> <span class="code-content language-python">        loss.backward()</span></span>
                    
                        <span class="line"><span class="line-number">149</span> <span class="code-content language-python">        self.optimizer.step()</span></span>
                    
                        <span class="line"><span class="line-number">150</span> <span class="code-content language-python">        self.update_step += 1</span></span>
                    
                        <span class="line"><span class="line-number">151</span> <span class="code-content language-python">        if self.update_step % self.step_c == 0:</span></span>
                    
                        <span class="line"><span class="line-number">152</span> <span class="code-content language-python">            self.synchronize_value_nn()</span></span>
                    
                        <span class="line"><span class="line-number">153</span> <span class="code-content language-python">            self.logger.tb_scalar('loss', loss.item(), self.update_step)</span></span>
                    
                        <span class="line"><span class="line-number">154</span> <span class="code-content language-python">            self.logger.tb_scalar('q', torch.mean(q_value), self.update_step)</span></span>
                    
                        <span class="line"><span class="line-number">155</span> <span class="code-content language-python">        return np.abs(diff_clipped.detach().cpu().numpy().astype(np.float32))</span></span>
                    
                        <span class="line"><span class="line-number">156</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">157</span> <span class="code-content language-python">    def value(self, phi_tensor: torch.Tensor) -> np.ndarray:</span></span>
                    
                        <span class="line"><span class="line-number">158</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">159</span> <span class="code-content language-python">        with torch.no_grad():</span></span>
                    
                        <span class="line"><span class="line-number">160</span> <span class="code-content language-python">            if phi_tensor.dim() == 3:</span></span>
                    
                        <span class="line"><span class="line-number">161</span> <span class="code-content language-python">                obs_input = phi_tensor.unsqueeze(0)</span></span>
                    
                        <span class="line"><span class="line-number">162</span> <span class="code-content language-python">            else:</span></span>
                    
                        <span class="line"><span class="line-number">163</span> <span class="code-content language-python">                obs_input = phi_tensor</span></span>
                    
                        <span class="line"><span class="line-number">164</span> <span class="code-content language-python">            self.value_nn.eval()</span></span>
                    
                        <span class="line"><span class="line-number">165</span> <span class="code-content language-python">            obs_input = image_normalization(obs_input)</span></span>
                    
                        <span class="line"><span class="line-number">166</span> <span class="code-content language-python">            state_action_values = self.value_nn(obs_input).cpu().detach().numpy()</span></span>
                    
                        <span class="line"><span class="line-number">167</span> <span class="code-content language-python">            return state_action_values</span></span>
                    
                        <span class="line"><span class="line-number">168</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">169</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">170</span> <span class="code-content language-python">class DQNAgent(Agent):</span></span>
                    
                        <span class="line"><span class="line-number">171</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">172</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">173</span> <span class="code-content language-python">    def __init__(self, input_frame_width: int, input_frame_height: int, action_space,</span></span>
                    
                        <span class="line"><span class="line-number">174</span> <span class="code-content language-python">                 mini_batch_size: int, replay_buffer_size: int, replay_start_size: int,</span></span>
                    
                        <span class="line"><span class="line-number">175</span> <span class="code-content language-python">                 learning_rate: float, step_c: int, model_saving_period: int,</span></span>
                    
                        <span class="line"><span class="line-number">176</span> <span class="code-content language-python">                 gamma: float, training_episodes: int, phi_channel: int, epsilon_max: float, epsilon_min: float,</span></span>
                    
                        <span class="line"><span class="line-number">177</span> <span class="code-content language-python">                 exploration_steps: int, device: torch.device, logger: Logger):</span></span>
                    
                        <span class="line"><span class="line-number">178</span> <span class="code-content language-python">        super(DQNAgent, self).__init__(logger)</span></span>
                    
                        <span class="line"><span class="line-number">179</span> <span class="code-content language-python">        self.action_dim = action_space.n</span></span>
                    
                        <span class="line"><span class="line-number">180</span> <span class="code-content language-python">        self.value_function = DQNValueFunction(phi_channel, self.action_dim, learning_rate, gamma, step_c,</span></span>
                    
                        <span class="line"><span class="line-number">181</span> <span class="code-content language-python">                                               model_saving_period, device, logger)</span></span>
                    
                        <span class="line"><span class="line-number">182</span> <span class="code-content language-python">        self.exploration_method = DecayingEpsilonGreedy(epsilon_max, epsilon_min, exploration_steps)</span></span>
                    
                        <span class="line"><span class="line-number">183</span> <span class="code-content language-python">        self.memory = UniformExperienceReplay(replay_buffer_size)</span></span>
                    
                        <span class="line"><span class="line-number">184</span> <span class="code-content language-python">        self.perception_mapping = DQNPerceptionMapping(phi_channel, input_frame_width, input_frame_height)</span></span>
                    
                        <span class="line"><span class="line-number">185</span> <span class="code-content language-python">        self.reward_shaping = DQNAtariReward()</span></span>
                    
                        <span class="line"><span class="line-number">186</span> <span class="code-content language-python">        self.device = device</span></span>
                    
                        <span class="line"><span class="line-number">187</span> <span class="code-content language-python">        self.mini_batch_size = mini_batch_size</span></span>
                    
                        <span class="line"><span class="line-number">188</span> <span class="code-content language-python">        self.replay_start_size = replay_start_size</span></span>
                    
                        <span class="line"><span class="line-number">189</span> <span class="code-content language-python">        self.training_episodes = training_episodes</span></span>
                    
                        <span class="line"><span class="line-number">190</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">191</span> <span class="code-content language-python">    def select_action(self, obs: np.ndarray, exploration_method: Exploration = None) -> np.ndarray:</span></span>
                    
                        <span class="line"><span class="line-number">192</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">193</span> <span class="code-content language-python">        if isinstance(exploration_method, RandomAction):</span></span>
                    
                        <span class="line"><span class="line-number">194</span> <span class="code-content language-python">            return exploration_method(self.action_dim)</span></span>
                    
                        <span class="line"><span class="line-number">195</span> <span class="code-content language-python">        else:</span></span>
                    
                </div>
            </div>
        
            <div class="section" id="section-9">
                <div class="docs">
                    <div class="section-link">
                        <a href="#section-9">#</a>
                    </div>
                    <h2></h2>
                     <div id="description-section-9"></div>
                    <script>
                        document.getElementById('description-section-9').innerHTML = marked(`obs_scaled = image_normalization(np.array(obs).astype(np.float32))`);
                    </script>
                </div>
                <div class="code">

                    
                        <span class="line"><span class="line-number">197</span> <span class="code-content language-python">            phi_tensor = torch.as_tensor(obs, device=self.device,dtype=torch.float32)</span></span>
                    
                        <span class="line"><span class="line-number">198</span> <span class="code-content language-python">            value_list = self.value_function.value(phi_tensor)[0]</span></span>
                    
                        <span class="line"><span class="line-number">199</span> <span class="code-content language-python">            if exploration_method is None:</span></span>
                    
                        <span class="line"><span class="line-number">200</span> <span class="code-content language-python">                return self.exploration_method(value_list)</span></span>
                    
                        <span class="line"><span class="line-number">201</span> <span class="code-content language-python">            else:</span></span>
                    
                        <span class="line"><span class="line-number">202</span> <span class="code-content language-python">                return exploration_method(value_list)</span></span>
                    
                        <span class="line"><span class="line-number">203</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">204</span> <span class="code-content language-python">    def store(self, obs, action, reward, next_obs, done, truncated):</span></span>
                    
                        <span class="line"><span class="line-number">205</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">206</span> <span class="code-content language-python">        self.memory.store(obs, np.array(action), np.array(reward), next_obs, np.array(done), np.array(truncated))</span></span>
                    
                        <span class="line"><span class="line-number">207</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">208</span> <span class="code-content language-python">    def train_step(self):</span></span>
                    
                        <span class="line"><span class="line-number">209</span> <span class="code-content language-python"></span></span>
                    
                        <span class="line"><span class="line-number">210</span> <span class="code-content language-python">        if len(self.memory) > self.replay_start_size:</span></span>
                    
                        <span class="line"><span class="line-number">211</span> <span class="code-content language-python">            samples = self.memory.sample(self.mini_batch_size)</span></span>
                    
                        <span class="line"><span class="line-number">212</span> <span class="code-content language-python">            self.value_function.update(samples)</span></span>
                    
                </div>
            </div>
        
    </div>
<script src="interactive.js"></script>
<script>
    function handleImages() {
        var images = document.querySelectorAll('p>img');
        images.forEach(function(img) {
            img.parentElement.style.textAlign = 'center';
            var modal = document.createElement('div');
            modal.id = 'modal';
            var modalContent = document.createElement('div');
            modal.appendChild(modalContent);
            var modalImage = document.createElement('img');
            modalContent.appendChild(modalImage);
            var span = document.createElement('span');
            span.classList.add('close');
            span.textContent = 'Ã—';
            modal.appendChild(span);

            img.onclick = function() {
                console.log('Image clicked');
                document.body.appendChild(modal);
                modalImage.src = this.src;
            };

            span.onclick = function() {
                document.body.removeChild(modal);
            };
        });
    }
    handleImages();
</script>
<script>
        // Function to set the correct Highlight.js theme based on the system theme
        function setHighlightTheme() {
            const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches;
            const styleLink = document.getElementById('highlight-style');
            if (isDarkMode) {
                styleLink.href = "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/atom-one-dark.min.css";
            } else {
                styleLink.href = "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/atom-one-light.min.css";
            }
        }

        // Set the initial theme
        setHighlightTheme();

        // Add event listener for system theme changes
        window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {
            setHighlightTheme();
        });

        // Initialize highlighting
        // hljs.highlightAll();
    </script>
</body>
</html>